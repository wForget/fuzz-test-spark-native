name: Common workflow

on:
  workflow_call:
    inputs:
      os:
        default: 'ubuntu-latest'
        required: false
        type: string
      java-version:
        default: '8'
        required: false
        type: string
      spark-version:
        default: '3.5.4'
        required: false
        type: string
      spark-binary-version:
        default: '3.5'
        required: false
        type: string
      scala-version:
        default: '2.12.17'
        required: false
        type: string
      scala-binary-version:
        default: '2.12'
        required: false
        type: string

permissions:
  issues: write

jobs:
  build-fuzz-test:
    name: Build fuzz Test
    runs-on: ${{ inputs.os }}
    steps:
      - uses: actions/checkout@v4
      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: ${{ inputs.java-version }}
      - name: Get cached fuzz test lib
        id: get-fuzz-test-cache
        uses: actions/cache@v4
        with:
          path: fuzz-test-spark-native-*.jar
          key: fuzz-test-spark-native-lib-${{ hashFiles('pom.xml', '**/*.scala', '**/*.java') }}
          enableCrossOsArchive: true
      - name: Build fuzz Test
        if: steps.get-fuzz-test-cache.outputs.cache-hit != 'true'
        run: |
          mvn clean package -DskipTests
          cp target/fuzz-test-spark-native-*.jar .

  build-comet:
    name: Build comet and run fuzz test
    needs: build-fuzz-test
    runs-on: ${{ inputs.os }}
    steps:
      - uses: actions/checkout@v4
      - name: Checkout Datafusion Comet
        uses: actions/checkout@v4
        with:
          repository: apache/datafusion-comet
          path: datafusion-comet
          ref: main
          fetch-depth: 1
      - name: Setup Rust & Java toolchain
        uses: ./.github/actions/setup-builder
        with:
          rust-version: 'stable'
          jdk-version: ${{ inputs.java-version }}
      - name: Get date
        id: get-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
      - name: Get cached Datafusion Comet lib
        id: get-comet-spark-cache
        uses: actions/cache/restore@v4
        with:
          path: comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}-*.jar
          key: comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}-${{ steps.get-date.outputs.date }}
      - name: Build Datafusion Comet
        if: steps.get-comet-spark-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          cd datafusion-comet
          PROFILES="-Pspark-${{ inputs.spark-binary-version }}" make release
          cp spark/target/comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}-*.jar ..
      - name: Cached Datafusion Comet lib
        if: steps.get-comet-spark-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}-*.jar
          key: comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}-${{ steps.get-date.outputs.date }}
      - name: Upload Datafusion Comet lib
        uses: actions/upload-artifact@v4
        with:
          name: comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}
          path: |
            comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}-*.jar
          overwrite: true
      - name: Setup Spark
        uses: ./.github/actions/setup-spark
        with:
          spark-version: ${{ inputs.spark-version }}
          scala-binary-version: ${{ inputs.scala-binary-version }}
      - name: Run fuzz test with comet on spark
        uses: ./.github/actions/run-fuzz-test
        with:
          native-engine: comet
          native-engine-jar: comet-spark-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}-*.jar
      - name: Report fuzz test result of Comet
        uses: ./.github/actions/report-fuzz-test
        with:
          native-engine: comet
          github-token: ${{ secrets.GITHUB_TOKEN }}
#      - name: Run fuzz test with comet on spark
#        shell: bash
#        run: |
#          FUZZ_TEST_JAR=$(ls fuzz-test-spark-native-*.jar)
#          mv comet-spark-spark* $SPARK_HOME/jars
#          # Generate data
#          $SPARK_HOME/bin/spark-submit \
#            --master local \
#            --class cn.wangz.spark.fuzz.Main \
#            $FUZZ_TEST_JAR \
#            data --num-files=2 --num-rows=200 --num-columns=100
#          # Generate queries
#          $SPARK_HOME/bin/spark-submit \
#            --master local \
#            --class cn.wangz.spark.fuzz.Main \
#            $FUZZ_TEST_JAR \
#            queries --num-files=2 --num-queries=500
#          # Run queries
#          $SPARK_HOME/bin/spark-submit \
#              --master local \
#              --class cn.wangz.spark.fuzz.Main \
#              $FUZZ_TEST_JAR \
#              run --native-engine=comet --num-files=2 --filename=queries.sql
#      - name: Upload Comet lib
#        uses: actions/upload-artifact@v4
#        with:
#          name: datafusion-comet-spark-${{ github.run_id }}
#          path: |
#            datafusion-comet/spark/target/comet-spark-spark${{inputs.spark-binary-version}}_${{inputs.scala-binary-version}}-*.jar
#          retention-days: 1 # remove the artifact after 1 day, only valid for this workflow
#          overwrite: true

  build-blaze:
    name: Build blaze and run fuzz test
    needs: build-fuzz-test
    runs-on: ${{ inputs.os }}
    steps:
      - uses: actions/checkout@v4
      - name: Checkout Blaze
        uses: actions/checkout@v4
        with:
          repository: kwai/blaze
          path: blaze
          ref: master
          fetch-depth: 1
      - name: Setup Rust & Java toolchain
        uses: ./.github/actions/setup-builder
        with:
          rust-version: 'stable'
          jdk-version: ${{ inputs.java-version }}
      - name: Setup Maven
        uses: ./.github/actions/setup-maven
      - name: Get date
        id: get-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
      - name: Get cached Blaze lib
        id: get-blaze-spark-cache
        uses: actions/cache/restore@v4
        with:
          path: blaze-engine-spark-${{inputs.spark-binary-version}}-*.jar
          key: blaze-spark${{ inputs.spark-binary-version }}-${{ steps.get-date.outputs.date }}
      - name: Build Blaze
        if: steps.get-blaze-spark-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          cd blaze
          mvn clean package -Pspark-${{ inputs.spark-binary-version }} -Prelease
          cp target/blaze-engine-spark-${{inputs.spark-binary-version}}-*.jar ..
      - name: Cached Blaze lib
        if: steps.get-blaze-spark-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: blaze-engine-spark-${{inputs.spark-binary-version}}-*.jar
          key: blaze-spark${{ inputs.spark-binary-version }}-${{ steps.get-date.outputs.date }}
      - name: Setup Spark
        uses: ./.github/actions/setup-spark
        with:
          spark-version: ${{ inputs.spark-version }}
          scala-binary-version: ${{ inputs.scala-binary-version }}
      - name: Run fuzz test with blaze on spark
        uses: ./.github/actions/run-fuzz-test
        with:
          native-engine: blaze
          native-engine-jar: blaze-engine-spark-${{inputs.spark-binary-version}}-*.jar
      - name: Report fuzz test result of Blaze
        uses: ./.github/actions/report-fuzz-test
        with:
          native-engine: blaze
          github-token: ${{ secrets.GITHUB_TOKEN }}
#      - name: Upload Blaze lib
#        uses: actions/upload-artifact@v4
#        with:
#          name: Blaze-spark-${{ github.run_id }}
#          path: |
#            blaze/target/blaze-engine-spark-${{inputs.spark-binary-version}}-*.jar
#          retention-days: 1 # remove the artifact after 1 day, only valid for this workflow
#          overwrite: true

  build-gluten:
    name: Build gluten and run fuzz test
    needs: build-fuzz-test
    runs-on: ${{ inputs.os }}
    steps:
      - uses: actions/checkout@v4
      - name: Checkout Gluten
        uses: actions/checkout@v4
        with:
          repository: apache/incubator-gluten
          path: incubator-gluten
          ref: main
          fetch-depth: 1
      - name: Setup Rust & Java toolchain
        uses: ./.github/actions/setup-builder
        with:
          jdk-version: ${{ inputs.java-version }}
      - name: Setup Maven
        uses: ./.github/actions/setup-maven
      - name: Get date
        id: get-date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
      - name: Get cached gluten lib
        id: get-gluten-spark-cache
        uses: actions/cache/restore@v4
        with:
          path: gluten-velox-bundle-spark*.jar
          key: gluten-spark${{ inputs.spark-binary-version }}-${{ steps.get-date.outputs.date }}
      - name: Get cached gluten ccache
        id: gluten-ccache-cache
        uses: actions/cache@v4
        with:
          path: incubator-gluten/.ccache
          key: ccache-centos7-release-default-${{ steps.get-date.outputs.date }}
          restore-keys: |
            ccache-centos7-release-default
      - name: Build Gluten
        if: steps.get-gluten-spark-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          cd incubator-gluten
          docker run -v $GITHUB_WORKSPACE/incubator-gluten:/work -w /work apache/gluten:vcpkg-centos-7 bash -c "
            df -a
            cd /work
            export CCACHE_DIR=/work/.ccache
            bash dev/ci-velox-buildstatic-centos-7.sh
            ccache -s
            mkdir -p /work/.m2/repository/org/apache/arrow/
            cp -r /root/.m2/repository/org/apache/arrow/* /work/.m2/repository/org/apache/arrow/
          "
          mkdir -p ~/.m2/repository/org/apache/arrow
          cp -r $GITHUB_WORKSPACE/incubator-gluten/.m2/repository/org/apache/arrow/* ~/.m2/repository/org/apache/arrow/
          mvn clean package -Pbackends-velox -Pceleborn -Puniffle -Pspark-${{ inputs.spark-binary-version }} -DskipTests
          cp package/target/gluten-velox-bundle-spark*.jar ..
      - name: Cached Gluten lib
        if: steps.get-gluten-spark-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: gluten-velox-bundle-spark*.jar
          key: gluten-spark${{ inputs.spark-binary-version }}-${{ steps.get-date.outputs.date }}
      - name: Upload Gluten lib
        uses: actions/upload-artifact@v4
        with:
          name: gluten-velox-bundle-spark${{ inputs.spark-binary-version }}_${{ inputs.scala-binary-version }}
          path: |
            gluten-velox-bundle-spark*.jar
          overwrite: true
      - name: Setup Spark
        uses: ./.github/actions/setup-spark
        with:
          spark-version: ${{ inputs.spark-version }}
          scala-binary-version: ${{ inputs.scala-binary-version }}
      - name: Run fuzz test with gluten on spark
        uses: ./.github/actions/run-fuzz-test
        with:
          native-engine: gluten
          native-engine-jar: gluten-velox-bundle-spark*.jar
      - name: Report fuzz test result of Gluten
        uses: ./.github/actions/report-fuzz-test
        with:
          native-engine: gluten
          github-token: ${{ secrets.GITHUB_TOKEN }}
