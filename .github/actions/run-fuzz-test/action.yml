name: setup-spark
description: 'Run fuzz test'
inputs:
  native-engine:
    description: 'type of spark native engine (eg. blaze/comet/gluten)'
    required: true
  native-engine-jar:
    description: 'native engine jar file'
    required: true
  data-exclude-negative-zero:
    description: 'exclude negative zero from fuzz test'
    required: false
    default: 'true'
runs:
  using: composite
  steps:
#    - name: Download fuzz test lib
#      uses: actions/download-artifact@v4
#      with:
#        name: fuzz-test-spark-${{ github.run_id }}
    - name: Get cached fuzz test lib
      id: get-fuzz-test-cache
      uses: actions/cache/restore@v4
      with:
        path: fuzz-test-spark-native-*.jar
        key: fuzz-test-spark-native-lib-${{ hashFiles('pom.xml', '**/*.scala', '**/*.java') }}
        restore-keys:
          fuzz-test-spark-native-lib-
        enableCrossOsArchive: true
        fail-on-cache-miss: true
    - name: Copy native engine jar to spark jars
      shell: bash
      run: |
        cp ${{ inputs.native-engine-jar }} $SPARK_HOME/jars
    - name: Generate data
      shell: bash
      run: |
        FUZZ_TEST_JAR=$(ls fuzz-test-spark-native-*.jar)
        OPTS="--num-files=2 --num-rows=200 --num-columns=100"
        if [[ "${{ inputs.data-exclude-negative-zero }}" == "true" ]]; then
          OPTS="$OPTS --exclude-negative-zero"
        fi
        $SPARK_HOME/bin/spark-submit \
          --master local \
          --class cn.wangz.spark.fuzz.Main \
          $FUZZ_TEST_JAR \
          data $OPTS
    - name: Generate queries
      shell: bash
      run: |
        FUZZ_TEST_JAR=$(ls fuzz-test-spark-native-*.jar)
        $SPARK_HOME/bin/spark-submit \
          --master local \
          --class cn.wangz.spark.fuzz.Main \
          $FUZZ_TEST_JAR \
          queries --num-files=2 --num-queries=2000
    - name: Run queries
      shell: bash
      run: |
        FUZZ_TEST_JAR=$(ls fuzz-test-spark-native-*.jar)
        $SPARK_HOME/bin/spark-submit \
          --master local \
          --class cn.wangz.spark.fuzz.Main \
          --conf spark.driver.extraJavaOptions="--add-modules=jdk.incubator.vector -Dio.netty.tryReflectionSetAccessible=true --enable-native-access=ALL-UNNAMED" \
          $FUZZ_TEST_JAR \
          run --native-engine=${{ inputs.native-engine }} --num-files=2 --filename=queries.sql
